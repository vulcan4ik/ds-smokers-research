# Data Science Project Template

This repo is inspired by the [Docker for Datascience book](https://www.amazon.com/Docker-Data-Science-Extensible-Infrastructure/dp/1484230116). It's a Docker image with a data science environment based on the [jupyter/datascience-notebook](https://hub.docker.com/r/jupyter/datascience-notebook/) with pandas, matplotlib, scipy, seaborn and scikit-learn pre-installed.

–ì–æ—Ç–æ–≤–∞—è —Å—Ä–µ–¥–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞ Data Science –ø—Ä–æ–µ–∫—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Docker, Jupyter Lab –∏ PostgreSQL.

## To start new Data Science project (–ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç)

### 1. –ö–ª–æ–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π

Clone the repository:
Create a new directory, cd into it, and then run

```
git clone https://github.com/vulcan4ik/data-science-project-template.git
cd data-science-project-template
```

Or you can just download it as a zip and use it without git.

### 2. Add your favorite Python modules to ./docker/jupyter/requirements.txt. For example:

```
xgboost
tensorflow==1.6.0
```

Or use pip install right in jupyter (don't forget ! in front of the command)

```
!pip install your_package
```

### 3. Start containers(–ó–∞–ø—É—Å—Ç–∏—Ç–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã)

```
docker-compose up
```
–ü—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ Docker —Å–∫–∞—á–∞–µ—Ç –æ–±—Ä–∞–∑—ã –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç –≤—Å–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (–º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å 5-10 –º–∏–Ω—É—Ç).
### 4. Open Jupyter Lab
Copy a jupyter url from terminal and open it in your browser.
 Open Jupyter Lab:
http://localhost:8888
### 5. Create your notebooks

Find an `examples.ipynb` notebook in ipynb folder. Create your own notebooks.

### 6. Work with data

Copy your data into `./data` and read it in Jupyter. You can also upload data into PostgreSQL, which is running in its own container along with Jupyter (see examples notebook for details).

–í—Å—ë, —á—Ç–æ –≤—ã —Å–æ–∑–¥–∞—ë—Ç–µ –≤ Jupyter –≤–Ω—É—Ç—Ä–∏ –ø–∞–ø–∫–∏ /home/jovyan/work, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –Ω–∞ –≤–∞—à–µ–º –∫–æ–º–ø—å—é—Ç–µ—Ä–µ –≤ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞.

### 7. Stop containers

```
docker-compose down
```

8. Update images
```
docker-compose build --pull
```

9. Clean Docker's mess

```
docker rmi -f $(docker images -qf dangling=true)
```

Sometimes it is useful to remove all docker's data.

```
docker system prune
```

## üóÑÔ∏è –†–∞–±–æ—Ç–∞ —Å PostgreSQL

### –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∏–∑ Jupyter
#### –ß–µ—Ä–µ–∑ psycopg2
```
import psycopg2 as pg2
from sqlalchemy import create_engine, text
```

```
con = pg2.connect(
    host='this_postgres',
    user='postgres',
    password='password',
    database='postgres')
```

#### –ß–µ—Ä–µ–∑ SQLAlchemy

```
engine = create_engine('postgresql://postgres:password@this_postgres:5432/postgres')
```    

## üõ†Ô∏è –ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã

### –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã

`docker-compose down`



### –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏ —É–¥–∞–ª–∏—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö

`docker-compose down -v`


### –ü–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å –æ–±—Ä–∞–∑—ã –ø–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è requirements.txt
```
docker-compose build --no-cache
docker-compose up
```

### –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤

docker-compose logs jupyter
docker-compose logs postgres

text

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫

1. –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ `docker/jupyter/requirements.txt`
2. –ü–µ—Ä–µ—Å–æ–±–µ—Ä–∏—Ç–µ –æ–±—Ä–∞–∑:
```
docker-compose down
docker-compose build
docker-compose up
```


## üîß –ö–∞—Å—Ç–æ–º–∏–∑–∞—Ü–∏—è

### –ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø–æ—Ä—Ç–∞ Jupyter

–í `docker-compose.yml`:
ports:

"9999:8888" # –¢–µ–ø–µ—Ä—å –¥–æ—Å—Ç—É–ø–µ–Ω –Ω–∞ http://localhost:9999



### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏

–í `docker-compose.yml` –∏–∑–º–µ–Ω–∏—Ç–µ –∫–æ–º–∞–Ω–¥—É:
`command: start-notebook.py --ServerApp.token='your-secret-token'`


### –ù–∞—Å—Ç—Ä–æ–π–∫–∞ PostgreSQL

–ò–∑–º–µ–Ω–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –≤ `docker-compose.yml`:
environment:

POSTGRES_PASSWORD: your_password
POSTGRES_USER: your_user
POSTGRES_DB: your_database

##  License

This project is free to use for educational purposes.